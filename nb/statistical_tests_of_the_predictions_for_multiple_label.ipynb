{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the cross validation intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import metrics\n",
    "from bionlp.util import fs, io\n",
    "\n",
    "DATA_PATH = '../data/chmannot/filtx'\n",
    "METHODS = ['RandomForest', 'RbfSVM102-2', 'RbfSVM103-2', 'RbfSVM102-3', 'RbfSVM103-3', 'L1-LinSVC', 'Perceptron', 'MNB', 'MEM', 'ExtraTrees']\n",
    "LABEL_NUM = 10\n",
    "\n",
    "lb_scores = []\n",
    "for lb in xrange(LABEL_NUM):\n",
    "    scores = dict([(m, []) for m in METHODS])\n",
    "    for method in METHODS:\n",
    "        fpaths = sorted([fpath for fpath in fs.listf(DATA_PATH, pattern='pred_crsval_[0-9]*_%s_%i.npz' % (method.replace(' ', '_').lower(), lb), full_path=True)])\n",
    "        for fpath in fpaths:\n",
    "            npz_file = io.read_npz(fpath)\n",
    "            pred_lb, true_lb = npz_file['pred_lb'], npz_file['true_lb']\n",
    "            micro_fscore = metrics.fbeta_score(true_lb, pred_lb, beta=1, average='micro')\n",
    "            scores[method].append(micro_fscore)\n",
    "    lb_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the t-test and the rank-sum test of the pairwise methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "EQVAR_PVAL = 0.05\n",
    "\n",
    "dummy_arr = np.zeros((len(METHODS), len(METHODS)), dtype='float32')\n",
    "\n",
    "ttest_dfs, ttest_pval_dfs, rnksm_dfs, rnksm_pval_dfs = [[] for x in range(4)]\n",
    "for lb, scores in enumerate(lb_scores):\n",
    "    ttest_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "    ttest_pval_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "    rnksm_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "    rnksm_pval_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "\n",
    "    for m_pair in itertools.combinations(METHODS, 2):\n",
    "        lvn = stats.levene(scores[m_pair[0]], scores[m_pair[1]])\n",
    "        equal_var = lvn.pvalue < EQVAR_PVAL\n",
    "        ttest = stats.ttest_ind(scores[m_pair[0]], scores[m_pair[1]], equal_var=equal_var)\n",
    "        rnksm = stats.ranksums(scores[m_pair[0]], scores[m_pair[1]])\n",
    "        ttest_df.ix[m_pair], ttest_pval_df.ix[m_pair] = ttest.statistic, ttest.pvalue\n",
    "        rnksm_df.ix[m_pair], rnksm_pval_df.ix[m_pair] = rnksm.statistic, rnksm.pvalue\n",
    "\n",
    "    ttest_dfs.append(ttest_df)\n",
    "    ttest_pval_dfs.append(ttest_pval_df)\n",
    "    rnksm_dfs.append(rnksm_df)\n",
    "    rnksm_pval_dfs.append(rnksm_pval_df)\n",
    "    ttest_df.to_excel('ttest_%i.xlsx' % lb)\n",
    "    ttest_pval_df.to_excel('ttest_pval_%i.xlsx' % lb)\n",
    "    rnksm_df.to_excel('rnksm_%i.xlsx' % lb)\n",
    "    rnksm_pval_df.to_excel('rnksm_pval_%i.xlsx' % lb)\n",
    "ttest_df_avg = pd.DataFrame(np.array([df.as_matrix() for df in ttest_dfs]).mean(axis=0), index=METHODS, columns=METHODS)\n",
    "ttest_pval_df_avg = pd.DataFrame(np.array([df.as_matrix() for df in ttest_pval_dfs]).mean(axis=0), index=METHODS, columns=METHODS)\n",
    "rnksm_df_avg = pd.DataFrame(np.array([df.as_matrix() for df in rnksm_dfs]).mean(axis=0), index=METHODS, columns=METHODS)\n",
    "rnksm_pval_df_avg = pd.DataFrame(np.array([df.as_matrix() for df in rnksm_pval_dfs]).mean(axis=0), index=METHODS, columns=METHODS)\n",
    "\n",
    "ttest_df_avg.to_excel('ttest_avg.xlsx')\n",
    "ttest_pval_df_avg.to_excel('ttest_pval_avg.xlsx')\n",
    "rnksm_df_avg.to_excel('rnksm_avg.xlsx')\n",
    "rnksm_pval_df_avg.to_excel('rnksm_pval_avg.xlsx')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
