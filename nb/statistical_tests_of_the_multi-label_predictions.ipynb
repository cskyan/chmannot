{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the cross validation intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import metrics\n",
    "from bionlp.util import fs, io\n",
    "\n",
    "DATA_PATH = '../data/chmannot/origcmp'\n",
    "METHODS = ['UDT-RF', 'DF-RbfSVM', 'MNB', 'MEM']\n",
    "\n",
    "scores = dict([(m, []) for m in METHODS])\n",
    "for method in METHODS:\n",
    "    fpaths = sorted([fpath for fpath in fs.listf(DATA_PATH, pattern='pred_crsval_[0-9]*_%s_.*' % method.replace(' ', '_').lower(), full_path=True)])\n",
    "    for fpath in fpaths:\n",
    "        npz_file = io.read_npz(fpath)\n",
    "        pred_lb, true_lb = npz_file['pred_lb'], npz_file['true_lb']\n",
    "        micro_fscore = metrics.fbeta_score(true_lb, pred_lb, beta=1, average='micro')\n",
    "        scores[method].append(micro_fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the t-test and the rank-sum test of the pairwise methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "EQVAR_PVAL = 0.05\n",
    "\n",
    "dummy_arr = np.zeros((len(METHODS), len(METHODS)), dtype='float32')\n",
    "ttest_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "ttest_pval_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "rnksm_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "rnksm_pval_df = pd.DataFrame(np.copy(dummy_arr), index=METHODS, columns=METHODS)\n",
    "\n",
    "for m_pair in itertools.combinations(METHODS, 2):\n",
    "    lvn = stats.levene(scores[m_pair[0]], scores[m_pair[1]])\n",
    "    equal_var = lvn.pvalue < EQVAR_PVAL\n",
    "    ttest = stats.ttest_ind(scores[m_pair[0]], scores[m_pair[1]], equal_var=equal_var)\n",
    "    rnksm = stats.ranksums(scores[m_pair[0]], scores[m_pair[1]])\n",
    "    ttest_df.ix[m_pair], ttest_pval_df.ix[m_pair] = ttest.statistic, ttest.pvalue\n",
    "    rnksm_df.ix[m_pair], rnksm_pval_df.ix[m_pair] = rnksm.statistic, rnksm.pvalue\n",
    "\n",
    "ttest_df.to_excel('ttest.xlsx')\n",
    "ttest_pval_df.to_excel('ttest_pval.xlsx')\n",
    "rnksm_df.to_excel('rnksm.xlsx')\n",
    "rnksm_pval_df.to_excel('rnksm_pval.xlsx')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
